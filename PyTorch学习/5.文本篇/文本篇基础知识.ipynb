{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自然语言处理基本原理\n",
    "## 自然语言处理概念\n",
    "- 自然语言是指汉语、英语、法语等人们日常使用的语言，是人类社会发展演变而来的语言，它是人类学习生活的重要工具。概括说来，自然语言是指人类社会约定俗成的，区别于如程序设计的语言的人工语言。\n",
    "- 自然语言处理，是指用计算机对自然语言的形、音、义等信息进行处理，即对字、词、句、篇章的输入、输出、识别、分析、理解、生成等的操作和加工。自然语言处理是关于计算机科学与人工智能的一个重要学科， **是语言学与数学、 计算机科学、人工智能之间互相作用的领域**，主要研究能实现人与计算机之间用自然语言进行有效通信的各种理论和方法，以实现人机间的信息交流， 例如能有效地实现自然语言通信的计算机软件系统。\n",
    "- 自然语言处理的具体表现形式包括机器翻译、文本摘要、文本分类、文本校对、信息抽取、语音合成、语音识别等。自然语言处理机制涉及两个流程，包括自然语言理解和自然语言生成。 **自然语言理解**是指计算机能够理解自然语言文本的意义， **自然语言生成**则是指能以自然语言文本来表达给定的意图。\n",
    "- 自然语言的理解和分析是一个层次化的过程，许多语言学家把这一过程分为五个层次，可以更好地体现语言本身的构成，五个层次分别是语音分析、词法分析、句法分析、语义分析和语用分析 。\n",
    "    - 语音分析是要根据音位规则，从语音流中区分出一个个独立的音素，再根据音位形态规则找出音节及其对应的词素或词。\n",
    "    - 词法分析是找出词汇的各个词素，从中获得语言学的信息。\n",
    "    - 句法分析是对句子和短语的结构进行分析，目的是要找出词、短语等的相互关系以及各自在句中的作用。\n",
    "    - 语义分析是找出词义、结构意义及其结合意义，从而确定语言所表达的真正含义或概念。\n",
    "    - 语用分析是研究语言所存在的外界环境对语言使用者所产生的影响。\n",
    "- 在人工智能领域或者是语音信息处理领域中， 学者们普遍认为采用图灵试验可以判断计算机是否理解了某种自然语言，具体的判别标准如下。\n",
    "    - **问答**，机器人能正确回答输入文本中的有关问题；\n",
    "    - **文摘生成**，机器有能力生成输入文本的摘要；\n",
    "    - **释义**，机器能用不同的词语和句型来复述其输入的文本；\n",
    "    - **翻译**，机器具有把一种语言翻译成另一种语言的能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自然语言处理过去十年主要进展\n",
    "- 自然语言处理自 20 世纪 50 年代末六十年代初兴起。 “图灵测试” 提出一般被认为是自然语言处理思想的开端， 20 世纪 50 年代到 70 年代自然语言处理主要采用基于规则的方法， 具有语句覆盖不全、 方法对开发者的计算机和语言学背景要求极高的等缺点，实用化较差。 后来发展过程中的代表性事件是丹尼尔·博布罗（Daniel Bobrow）在 1964 年发表的“Natural language input for a computer problem solving system”，以及约瑟夫·维森鲍姆（Joseph Weizenbaum）在 1966 年发表的 “ ELIZA-a computer program for the study of natural languagecommunication between man and machine”。 70 年代以后随着互联网的高速发展，丰富的语料库成为现实以及硬件不断更新完善，自然语言处理基于统计的方法逐渐代替了基于规则的方法。贾里尼克和他领导的 IBM 华生实验室是推动这一转变的关键，他们采用基于统计的方法，将当时的语音识别率从 70%提升到 90%。在这一阶段，自然语言处理基于数学模型和统计的方法取得了实质性的突破，从实验室走向实际应用。 90 年代中期以来，计算机的速度和存储量大幅增加，为自\n",
    "然语言处理改善了物质基础，使得语音和语言处理的商品化开发成为可能；同时期 Internet 商业化和网络技术的发展使得基于自然语言的信息检索和信息抽取的需求变得更加突出 。\n",
    "- 21 世纪，自然语言处理发展出神经网络语言模型、多任务学习、预训练语言模型等典型技术。从 2008 年到现在，在图像识别和语音识别领域的成果激励下，人们也逐渐开始引入深度学习来做自然语言处理研究， 由最初的词向量到 2013 年的 word2vec， 将深度学习与自然语言处理的结合推向了高潮， 并在机器翻译、问答系统、阅读理解等领域取得了一定成功。深度学习是一个多层的神经网络，从输入层开始经过逐层非线性的变化得到输出。从输入到输出做端到端的训练。 把输入到输出对的数据准备好，设计并训练一个神经网络，即可执行预想的任务。 RNN 已经是自然语言处理最常用的方法之一， GRU、 LSTM 等模型相继引发了一轮又一轮的热潮。 2014 年提出的 seq2seq 模型，被广泛应用到在机器翻译、文本摘要和图像字幕等任务中并取得很大成功，在实现人机自然通信方面发挥了关键性作用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN基本原理\n",
    "- 我们的目的是基于当前的输入与过去的输入序列，预测序列的下一个字符。循环神经网络引入一个隐藏变量$H$，用$H_t$表示$H$在时间步$t$的值。$H_t$的计算基于$X_t$和$H_{t-1}$，可以认为$H_t$记录了到当前字符为止的序列信息，利用$H_t$对序列的下一个字符进行预测。\n",
    "\n",
    "<img src=\"https://cdn.nlark.com/yuque/0/2021/png/1508544/1614241960312-4de5e22b-3195-4520-b218-60b4fb411dc5.png\"/>\n",
    "\n",
    "- 假设$\\boldsymbol{X}_t \\in \\mathbb{R}^{n \\times d}$是时间步$t$的小批量输入，$\\boldsymbol{H}_t  \\in \\mathbb{R}^{n \\times h}$是该时间步的隐藏变量，则：\n",
    "    - $\\boldsymbol{H}_t = \\phi(\\boldsymbol{X}_t \\boldsymbol{W}_{xh} + \\boldsymbol{H}_{t-1} \\boldsymbol{W}_{hh}  + \\boldsymbol{b}_h).$\n",
    "- 其中，$\\boldsymbol{W}_{xh} \\in \\mathbb{R}^{d \\times h}$，$\\boldsymbol{W}_{hh} \\in \\mathbb{R}^{h \\times h}$，$\\boldsymbol{b}_{h} \\in \\mathbb{R}^{1 \\times h}$，$\\phi$函数是非线性激活函数。由于引入了$\\boldsymbol{H}_{t-1} \\boldsymbol{W}_{hh}$，$H_{t}$能够捕捉截至当前时间步的序列的历史信息，就像是神经网络当前时间步的状态或记忆一样。由于$H_{t}$的计算基于$H_{t-1}$，上式的计算是循环的，使用循环计算的网络即循环神经网络（recurrent neural network）。\n",
    "- 在时间步$t$，输出层的输出为：$\\boldsymbol{O}_t = \\boldsymbol{H}_t \\boldsymbol{W}_{hq} + \\boldsymbol{b}_q.$\n",
    "- 其中，$\\boldsymbol{W}_{hq} \\in \\mathbb{R}^{h \\times q}$，$\\boldsymbol{b}_q \\in \\mathbb{R}^{1 \\times q}$。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "tianchi_metadata": {
   "competitions": [],
   "datasets": [],
   "description": "",
   "notebookId": "162702",
   "source": "dsw"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
