{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. torchvision.datasets\n",
    "- 常用数据集：\n",
    "\n",
    "<img src=\"https://cdn.nlark.com/yuque/0/2021/png/1508544/1614232281273-c127df7b-6114-4075-b875-471a9004e014.png\"/>\n",
    "\n",
    "- 每个数据集的API都是基本相同的。它们都有两个相同的参数：transform和target_transform\n",
    "- 我们就用最经典最简单的MNIST手写数字数据集作为例子，\n",
    "    - torchvision.datasets.MNIST(root: str, train: bool=True, transform: Optional[Callable]=None, target_transform: Optional[Callable]=None, download: bool=False)\n",
    "        - root：就是你想要保存MNIST数据集的位置，如果download是Flase的话，则会从目标位置读取数据集\n",
    "        - download：True的话就会自动从网上下载这个数据集，到root的位置\n",
    "        - train：True的话，数据集下载的是训练数据集；False的话则下载测试数据集\n",
    "        - transform：这个是对图像进行处理的transform，比方说旋转平移缩放，输入的是PIL格式的图像\n",
    "        - target_transform：这个是对图像标签进行处理的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./Datasets/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c96b147d52b04d96a5756b0abd458ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ./Datasets/MNIST/raw/train-images-idx3-ubyte.gz to ./Datasets/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./Datasets/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93fcf7c4a80147dc806b3c0e384af07b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ./Datasets/MNIST/raw/train-labels-idx1-ubyte.gz to ./Datasets/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./Datasets/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6420d6225c354d489d1061b4eea76b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ./Datasets/MNIST/raw/t10k-images-idx3-ubyte.gz to ./Datasets/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./Datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ab0a02af39446881e6f6307c0956aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ./Datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./Datasets/MNIST/raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/.local/lib/python3.6/site-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "mydataset = torchvision.datasets.MNIST(root='./Datasets',\n",
    "                                      train=True,\n",
    "                                      transform=torchvision.transforms.ToTensor(),\n",
    "                                      target_transform=None,\n",
    "                                      download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. torchvision.models\n",
    "- 预训练模型中torchvision提供了很多种，大体分为下面四类：    \n",
    "    - Classification\n",
    "    - Semantic Segmentation\n",
    "    - Object Detection, Instance Segmentation and Person Keypoint Detection\n",
    "    - Video classification\n",
    "- 分别是分类模型、语义模型、目标检测模型和视频分类模型。\n",
    "- 在torch1.7.1版本中，主要包含下面的预训练模型：\n",
    "    - AlexNet\n",
    "    - VGG\n",
    "    - ResNet\n",
    "    - SqueezeNet\n",
    "    - DenseNet\n",
    "    - Inception v3\n",
    "    - GoogLeNet\n",
    "    - ShuffleNet v2\n",
    "    - MobileNet v2\n",
    "    - ResNeXt\n",
    "    - Wide ResNet\n",
    "    - MNASNet\n",
    "- 构建模型可以通过下面的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/.local/lib/python3.6/site-packages/torchvision/models/inception.py:77: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  ' due to scipy/scipy#11299), please set init_weights=True.', FutureWarning)\n",
      "/home/admin/.local/lib/python3.6/site-packages/torchvision/models/googlenet.py:73: FutureWarning: The default weight initialization of GoogleNet will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  ' due to scipy/scipy#11299), please set init_weights=True.', FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "resnet18 = models.resnet18()\n",
    "alexnet = models.alexnet()\n",
    "vgg16 = models.vgg16()\n",
    "squeezenet = models.squeezenet1_0()\n",
    "densenet = models.densenet161()\n",
    "inception = models.inception_v3()\n",
    "googlenet = models.googlenet()\n",
    "shufflenet = models.shufflenet_v2_x1_0()\n",
    "mobilenet = models.mobilenet_v2()\n",
    "resnext50_32x4d = models.resnext50_32x4d()\n",
    "wide_resnet50_2 = models.wide_resnet50_2()\n",
    "mnasnet = models.mnasnet1_0()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 这样构建的模型的权重值是随机的，只有结构是保存的。想要获取预训练的模型，则需要设置参数pretrained。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "squeezenet = models.squeezenet1_0(pretrained=True)\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "densenet = models.densenet161(pretrained=True)\n",
    "inception = models.inception_v3(pretrained=True)\n",
    "googlenet = models.googlenet(pretrained=True)\n",
    "shufflenet = models.shufflenet_v2_x1_0(pretrained=True)\n",
    "mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "resnext50_32x4d = models.resnext50_32x4d(pretrained=True)\n",
    "wide_resnet50_2 = models.wide_resnet50_2(pretrained=True)\n",
    "mnasnet = models.mnasnet1_0(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 模型比较\n",
    "- torchvision官方提供了一个不同模型在Imagenet 1-crop 的一个错误率的比较。可以一起来看看到底哪个模型比较好使。这里列了一些常见的模型。\n",
    "<img src=\"https://cdn.nlark.com/yuque/0/2021/png/1508544/1614235351066-be89492d-008f-4e33-ac7f-c6f0e519986c.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 练习题\n",
    "修改3.2迁移学习中的代码，改用torchvision.models里的模型，观察并比较不同模型之间的差别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "tianchi_metadata": {
   "competitions": [],
   "datasets": [],
   "description": "",
   "notebookId": "161483",
   "source": "dsw"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
