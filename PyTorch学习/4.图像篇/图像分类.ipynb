{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络（CNN）\n",
    "- 对于计算机视觉的分类任务，在很长一段时间里流行的是研究者通过经验与智慧所设计并生成的手工特征。这类图像分类研究的主要流程是：\n",
    "    - 获取图像数据集；\n",
    "    - 使用已有的特征提取函数生成图像的特征；\n",
    "    - 使用机器学习模型对图像的特征分类。\n",
    "- 卷积神经网络就是含有卷积层的神经网络，深度卷积神经网络的兴起改变了计算机视觉任务中手工设计特征的传统，引领了诸多影响深远的研究。\n",
    "\n",
    "## LeNet\n",
    "- LeNet作为一个早期用来识别手写数字图像的卷积神经网络，展示了通过梯度下降训练卷积神经网络可以达到手写数字识别在当时最先进的结果。如下图所示：\n",
    "<center/><img src=\"https://cdn.nlark.com/yuque/0/2021/svg/1508544/1616470769150-17a289a6-5684-442e-898d-ddf5e84145ee.svg\"/></center>\n",
    "\n",
    "- LeNet的模型结构分为卷积层块和全连接层块两个部分：\n",
    "    - 卷积层保留输入形状，使图像的像素在高和宽两个方向上的相关性均可能被有效识别，并且通过滑动窗口将同一卷积核与不同位置的输入重复计算，从而避免参数尺寸过大。\n",
    "    - 全连接层块将卷积层块的输出中每个样本展平，即输入形状将变成二维，其中第一维是小批量中的样本，第二维是每个样本展平后的向量表示，从而进行分类。\n",
    "\n",
    "## AlexNet\n",
    "- 2012年，AlexNet横空出世，使用了8层卷积神经网络，并以很大的优势赢得了ImageNet 2012图像识别挑战赛。\n",
    "- AlexNet与LeNet的设计理念非常相似，但相对较小的LeNet相比，AlexNet包含5层卷积和2层全连接隐藏层，以及1个全连接输出层，模型参数也大大增加。由于早期显存的限制，最早的AlexNet使用双数据流的设计，使一个GPU只需处理一半模型。如下图所示：\n",
    "<center/><img src=\"https://cdn.nlark.com/yuque/0/2021/png/1508544/1616471381245-3f28bb8d-a84a-44b0-a0b2-9c91145b0587.png\"/></center>  \n",
    "- AlexNet首次证明了神经网络以端到端（end-to-end）的方式学习到的特征可以超越手工设计的特征，从而一举打破计算机视觉研究的前状。\n",
    "\n",
    "## VGG\n",
    "- AlexNet在LeNet的基础上增加了3个卷积层，同时对网络的卷积窗口、输出通道数和构造顺序均做了大量的调整。\n",
    "- AlexNet指明了深度卷积神经网络可以取得出色的结果，基于这一个理念，牛津大学的实验室Visual Geometry Group实验室提出了VGG网络，提供了通过重复使用简单的基础块来构建深度模型的思路。VGG每个基础块组成规律是：连续使用数个相同的填充为1、窗口形状为3×3的卷积层后接上一个步幅为2、窗口形状为2×2的最大池化层。卷积层保持输入的高和宽不变，而池化层则对其减半。如下图所示：\n",
    "<center/><img src=\"https://cdn.nlark.com/yuque/0/2021/jpeg/1508544/1616471595648-5620d798-45f2-477e-bce0-dbfa20115c7d.jpeg\"/></center>  \n",
    "- 可以看到，每次经过基础块以后，网络会将输入的高和宽减半，直到最终高和宽变成7后传入全连接层。与此同时，输出通道数每次翻倍，直到变成512。因为每个卷积层的窗口大小一样，VGG这种高和宽减半以及通道翻倍的设计使得多数卷积层都有相同的模型参数尺寸和计算复杂度。\n",
    "\n",
    "## NiN\n",
    "- 之前介绍的LeNet、AlexNet和VGG在设计上的共同之处是：先以由卷积层构成的模块充分抽取空间特征，再以由全连接层构成的模块来输出分类结果。其中，AlexNet和VGG对LeNet的改进主要在于如何对这两个模块加宽（增加通道数）和加深。网络中的网络（NiN）提出了另外一个思路，即串联多个由卷积层和“全连接”层构成的小网络来构建一个深层网络。\n",
    "- 卷积层的输入和输出通常是四维数组（样本，通道，高，宽），而全连接层的输入和输出则通常是二维数组（样本，特征）。如果想在全连接层后再接上卷积层，则需要将全连接层的输出变换为四维，1×1卷积层可以看成全连接层，其中空间维度（高和宽）上的每个元素相当于样本，通道相当于特征。因此，NiN使用1×1卷积层来替代全连接层，从而使空间信息能够自然传递到后面的层中去。下图对比了NiN同AlexNet和VGG等网络在结构上的主要区别。\n",
    "<center/><img src=\"https://cdn.nlark.com/yuque/0/2021/svg/1508544/1616471725212-1ad26a46-a76d-40c5-a903-e921c59423e2.svg\"/></center>  \n",
    "- NiN块是NiN中的基础块。它由一个卷积层加两个充当全连接层的1×1卷积层串联而成。其中第一个卷积层的超参数可以自行设置，而第二和第三个卷积层的超参数一般是固定的。\n",
    "\n",
    "## GooLeNet\n",
    "- 在2014年的ImageNet图像识别挑战赛中，一个名叫GoogLeNet的网络结构大放异彩，它虽然在名字上向LeNet致敬，但在网络结构上已经很难看到LeNet的影子。GoogLeNet吸收了NiN中网络串联网络的思想，并在此基础上做了很大改进。GoogLeNet中的基础卷积块叫作Inception块，得名于同名电影《盗梦空间》（Inception）。与上NiN块相比，这个基础块在结构上更加复杂，如下图所示：\n",
    "<center/><img src=\"https://cdn.nlark.com/yuque/0/2021/svg/1508544/1616471806299-c2f191ba-cb6b-4a7c-8720-b8d9c4b7c802.svg\"/></center>  \n",
    "- Inception块里有4条并行的线路。前3条线路使用窗口大小分别是1×1、3×3和5×5的卷积层来抽取不同空间尺寸下的信息，其中中间2个线路会对输入先做1×1卷积来减少输入通道数，以降低模型复杂度。第四条线路则使用3×3最大池化层，后接1×1卷积层来改变通道数。4条线路都使用了合适的填充来使输入与输出的高和宽一致。最后将每条线路的输出在通道维上连结，并输入接下来的层中去。Inception块中可以自定义的超参数是每个层的输出通道数，以此来控制模型复杂度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion-mnist分类任务\n",
    "<center/><img src=\"https://cdn.nlark.com/yuque/0/2021/jpeg/1508544/1613798010557-8a28fd24-ca7f-443c-9c70-d2366010d5eb.jpeg\"/></center>\n",
    "\n",
    "## Fashion-mnist\n",
    "- [经典的MNIST数据集](http://yann.lecun.com/exdb/mnist/)包含了大量的手写数字。十几年来，来自机器学习、机器视觉、人工智能、深度学习领域的研究员们把这个数据集作为衡量算法的基准之一。你会在很多的会议，期刊的论文中发现这个数据集的身影。实际上，MNIST数据集已经成为算法作者的必测的数据集之一。有人曾经调侃道：“如果一个算法在MNIST不work，那么它就根本没法用；而如果它在MNIST上work，它在其它数据上也可能不work！”\n",
    "- **Fashion-mnist**的目的是要成为MNIST数据集的一个直接替代品。作为算法作者，你不需要修改任何代码，就可以直接使用这个数据集。**Fashion-mnist**的图片大小，训练、测试样本数及类别数与经典MNIST**完全相同**。\n",
    "- 这个数据集的样子大致如下（每个类别占三行）：\n",
    "<center/><img src=\"https://cdn.nlark.com/yuque/0/2021/jpeg/1508544/1614584630615-e95e380f-dfe9-48be-83ce-1b0ae488d42f.jpeg?x-oss-process=image/resize,w_633\"/></center>\n",
    "\n",
    "## 类别标注\n",
    "• 在Fashion-mnist数据集中，每个训练样本都按照以下类别进行了标注：\n",
    "\n",
    "|**标注编号**|**描述**|\n",
    "|---|---|\n",
    "|0|T-shirt/top（T恤）|\n",
    "|1|Trouser（裤子）|\n",
    "|2|Pullover（套衫）|\n",
    "|3|Dress（裙子）|\n",
    "|4|Coat（外套）|\n",
    "|5|Sandal（凉鞋）|\n",
    "|6|Shirt（汗衫）|\n",
    "|7|Sneaker（运动鞋）|\n",
    "|8|Bag（包）|\n",
    "|9|Ankle boot（踝靴）|\n",
    "\n",
    "## 任务描述\n",
    "- Fashion-mnist是一个替代[MNIST手写数字集](http://yann.lecun.com/exdb/mnist/)的图像数据集。它是由Zalando（一家德国的时尚科技公司）旗下的[研究部门](https://research.zalando.com/)提供。其涵盖了来自10种类别的共7万个不同商品的正面图片。Fashion-mnist的大小、格式和训练集/测试集划分与原始的MNIST完全一致。60000/10000的训练测试数据划分，28×28的灰度图片。你可以直接用它来测试你的机器学习和深度学习算法性能，且不需要改动任何的代码。\n",
    "- 本次任务需要针对Fashion-mnist数据集，设计、搭建、训练机器学习模型，能够尽可能准确地分辨出测试数据的标签。\n",
    "\n",
    "## 文档说明\n",
    "- 数据集文件分为训练集和测试集部分，对应文件如下：\n",
    "    - 训练数据：`train-images-idx3-ubyte.gz`\n",
    "    - 训练标签：`train-labels-idx1-ubyte.gz`\n",
    "    - 测试数据：`t10k-images-idx3-ubyte.gz`\n",
    "    \n",
    "## 评估说明\n",
    "### 评价指标\n",
    "- 本次任务采用 ACC（Accuracy）作为模型的评价标准。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码实现\n",
    "## 加载数据集\n",
    "-  FashionMNIST是28×28的灰度图片，60000/10000的训练测试数据划分，其涵盖了来自10种类别的共7万个不同商品的正面图片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "###################fashion mnist数据集加载######################\n",
    "def load_data_fashion_mnist(batch_size, resize=None, root='~/Datasets/FashionMNIST'):\n",
    "    \"\"\"Download the fashion mnist dataset and then load into memory.\"\"\"\n",
    "    trans = []\n",
    "    if resize:\n",
    "        trans.append(torchvision.transforms.Resize(size=resize))\n",
    "    trans.append(torchvision.transforms.ToTensor())\n",
    "    # 图像增强\n",
    "    transform = torchvision.transforms.Compose(trans)\n",
    "    \n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=transform)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform)\n",
    "    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_iter, test_iter\n",
    "#################################################################\n",
    "batch_size = 32\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像展示\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "def get_fashion_mnist_labels(labels):\n",
    "    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "    return [text_labels[int(i)] for i in labels]\n",
    "\n",
    "def show_fashion_mnist(images, labels):\n",
    "    \"\"\"Use svg format to display plot in jupyter\"\"\"\n",
    "    display.set_matplotlib_formats('svg')\n",
    "    # 这里的_表示我们忽略（不使用）的变量\n",
    "    _, figs = plt.subplots(1, len(images), figsize=(12, 12))\n",
    "    for f, img, lbl in zip(figs, images, labels):\n",
    "        f.imshow(img.view((96, 96)).numpy())\n",
    "        f.set_title(lbl)\n",
    "        f.axes.get_xaxis().set_visible(False)\n",
    "        f.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "# 读取训练数据集中第一个batch的数据\n",
    "train_data = iter(train_iter)\n",
    "images, labels = next(train_data)\n",
    "# 观察训练数据集中前10个样本的图像内容和文本标签\n",
    "labels = get_fashion_mnist_labels(labels)\n",
    "show_fashion_mnist(images[:10], labels[:10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型设计\n",
    "- 自行设计一个神经网络模型\n",
    "    - 卷积层 - 归一化 - 激活函数 - 池化层\n",
    "    - resnet_block1模块\n",
    "    - resnet_block2模块\n",
    "    - resnet_block3模块\n",
    "    - resnet_block4模块\n",
    "    - 全局平均池化层 - 展平 - 全连接层(output = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    # 可以设定输出通道数、是否使用额外的1x1卷积层来修改通道数以及卷积层的步幅。\n",
    "    def __init__(self, in_c, out_c, c1, c2, c3, c4, use_1x1conv=False, stride=1):\n",
    "        super(Residual, self).__init__()\n",
    "        # 线路1，单1 x 1卷积层\n",
    "        self.p1_1 = nn.Conv2d(in_c, c1, kernel_size=1, stride=stride)\n",
    "        # 线路2，1 x 1卷积层后接3 x 3卷积层\n",
    "        self.p2_1 = nn.Conv2d(in_c, c2[0], kernel_size=1, stride=stride)\n",
    "        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "        # 线路3，1 x 1卷积层后接5 x 5卷积层\n",
    "        self.p3_1 = nn.Conv2d(in_c, c3[0], kernel_size=1, stride=stride)\n",
    "        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)\n",
    "        # 线路4，3 x 3最大池化层后接1 x 1卷积层\n",
    "        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.p4_2 = nn.Conv2d(in_c, c4, kernel_size=1, stride=stride)\n",
    "\n",
    "        if use_1x1conv:\n",
    "            self.conv1 = nn.Conv2d(in_c, out_c, kernel_size=1, stride=stride)\n",
    "        else:\n",
    "            self.conv1 = None\n",
    "        self.bn = nn.BatchNorm2d(out_c)\n",
    "\n",
    "    def forward(self, X):\n",
    "        p1 = F.relu(self.p1_1(X))\n",
    "        p2 = F.relu(self.p2_2(F.relu(self.p2_1(X))))\n",
    "        p3 = F.relu(self.p3_2(F.relu(self.p3_1(X))))\n",
    "        p4 = F.relu(self.p4_2(self.p4_1(X)))\n",
    "        Y = self.bn(torch.cat((p1, p2, p3, p4), dim=1))\n",
    "\n",
    "        if self.conv1:\n",
    "            X = self.conv1(X)\n",
    "        return F.relu(Y + X)\n",
    "\n",
    "\n",
    "def resnet_block(in_c, out_c, c1, c2, c3, c4, num_residuals, first_block=False):\n",
    "    if first_block:\n",
    "        assert in_c == out_c # 第一个模块的通道数同输入通道数一致\n",
    "    blk = []\n",
    "    for i in range(num_residuals):\n",
    "        if i == 0 and not first_block:\n",
    "            blk.append(Residual(in_c, out_c, c1, c2, c3, c4, use_1x1conv=True, stride=2))\n",
    "        else:\n",
    "            blk.append(Residual(out_c, out_c, c1, c2, c3, c4))\n",
    "    return nn.Sequential(*blk)\n",
    "\n",
    "\n",
    "class GlobalAvgPool2d(nn.Module):\n",
    "    # 全局平均池化层可通过将池化窗口形状设置成输入的高和宽实现\n",
    "    def __init__(self):\n",
    "        super(GlobalAvgPool2d, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return F.avg_pool2d(x, kernel_size=x.size()[2:])\n",
    "\n",
    "\n",
    "class FlattenLayer(torch.nn.Module):  #展平操作\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], -1)\n",
    "\n",
    "# torch.nn.Sequential是一个Sequential容器，模块将按照构造函数中传递的顺序添加到模块中。\n",
    "net = nn.Sequential(\n",
    "    \t# 添加第一个卷积层，调用了nn里面的Conv2d()\n",
    "        nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "        # 进行数据的归一化处理\n",
    "    \tnn.BatchNorm2d(32),\n",
    "    \t# 修正线性单元，是一种人工神经网络中常用的激活函数\n",
    "        nn.ReLU(),\n",
    "    \t# 再进行最大池化处理\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "# 依次添加resnet_block模块\n",
    "net.add_module(\"resnet_block1\", resnet_block(32, 32, 8, (4, 8), (4, 8), 8, 2, first_block=True))\n",
    "net.add_module(\"resnet_block2\", resnet_block(32, 80, 16, (16, 32), (8, 16), 16, 2))\n",
    "net.add_module(\"resnet_block3\", resnet_block(80, 192, 32, (32, 64), (32, 64), 32, 2))\n",
    "net.add_module(\"resnet_block4\", resnet_block(192, 320, 64, (64, 128), (32, 64), 64, 2))\n",
    "# 添加GlobalAvgPool2d模块\n",
    "net.add_module(\"global_avg_pool\", GlobalAvgPool2d()) # GlobalAvgPool2d的输出: (Batch, 256, 1, 1)\n",
    "# 添加FlattenLayer模块，再接一个全连接层\n",
    "net.add_module(\"fc\", nn.Sequential(FlattenLayer(), nn.Linear(320, 10)))\n",
    "# 模型定义-ResNet\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('打印 1*1*96*96 输入经过每个模块后的shape')\n",
    "X = torch.rand((1, 1, 96, 96))\n",
    "for name, layer in net.named_children():\n",
    "    X = layer(X)\n",
    "    print(name, ' output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, device=torch.device('cpu')):\n",
    "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
    "    acc_sum, n = torch.tensor([0], dtype=torch.float32, device=device), 0\n",
    "    for X, y in data_iter:\n",
    "        # If device is the GPU, copy the data to the GPU.\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            y = y.long()\n",
    "            # [[0.2 ,0.4 ,0.5 ,0.6 ,0.8] ,[ 0.1,0.2 ,0.4 ,0.3 ,0.1]] => [ 4 , 2 ]\n",
    "            acc_sum += torch.sum((torch.argmax(net(X), dim=1) == y))\n",
    "            n += y.shape[0]\n",
    "    return acc_sum.item() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ch(net, train_iter, test_iter, criterion, num_epochs, device, lr=None):\n",
    "    \"\"\"Train and evaluate a model with CPU or GPU.\"\"\"\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)  # 优化函数\n",
    "    best_test_acc = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum = torch.tensor([0.0], dtype=torch.float32, device=device)\n",
    "        train_acc_sum = torch.tensor([0.0], dtype=torch.float32, device=device)\n",
    "        n, start = 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            net.train()\n",
    "\n",
    "            optimizer.zero_grad()  # 清空梯度\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_hat = net(X)\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                y = y.long()\n",
    "                train_l_sum += loss.float()\n",
    "                train_acc_sum += (torch.sum((torch.argmax(y_hat, dim=1) == y))).float()\n",
    "                n += y.shape[0]\n",
    "        test_acc = evaluate_accuracy(test_iter, net, device)  # 测试验证集\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
    "              'time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc,\n",
    "                 time.time() - start))\n",
    "        if test_acc > best_test_acc:\n",
    "            print('find best! save at model/best.pth')\n",
    "            best_test_acc = test_acc\n",
    "            torch.save(net.state_dict(), 'model/best.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数设置\n",
    "lr, num_epochs = 0.001, 7\n",
    "criterion = nn.CrossEntropyLoss()   #交叉熵描述了两个概率分布之间的距离，交叉熵越小说明两者之间越接近\n",
    "train_ch(net, train_iter, test_iter, criterion, num_epochs, device, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作业\n",
    "试从神经网络模型的自行设计角度出发，提升一下测试集精度，并感受一下模型改变造成的影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "tianchi_metadata": {
   "competitions": [],
   "datasets": [],
   "description": "",
   "notebookId": "177420",
   "source": "dsw"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
