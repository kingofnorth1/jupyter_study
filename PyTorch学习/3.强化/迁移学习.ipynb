{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "8335625d-4a70-4736-9cd3-e4ba01ce393e"
   },
   "source": [
    "- 在深度学习模型日益庞大的今天，并非所有人都能满足从头开始训练一个模型的软硬件条件，稀缺的数据和昂贵的计算资源都是我们需要面对的难题。迁移学习可以帮助我们缓解在数据和计算资源上的尴尬。作为当前深度学习领域中最重要的方法论之一，迁移学习有着自己自身的理论依据和实际效果验证。\n",
    "- 作为一门实验性学科，深度学习通常需要反复的实验和结果论证。在现在和将来，是否有海量的数据资源和强大的计算资源，这是决定学界和业界深度学习和人工智能发展的关键因素。通常情况下，获取海量的数据资源对于企业而言并非易事，尤其是对于像医疗等特定领域，要想做一个基于深度学习的医学影像的辅助诊断系统，大量且高质量的打标数据非常关键。但通常而言，不要说高质量，就是想获取大量的医疗数据就已困难重重。\n",
    "- 那怎么办呢？是不是获取不了海量的数据研究就一定进行不下去了？当然不是。因为我们有迁移学习。那究竟什么是迁移学习？顾名思义，迁移学习就是利用数据、任务或模型之间的相似性，将在旧的领域学习过或训练好的模型，应用于新的领域这样的一个过程。从这段定义里面，我们可以窥见迁移学习的关键点所在，即新的任务与旧的任务在数据、任务和模型之间的相似性。\n",
    "- 本节我们介绍迁移学习中的一种常用技术：微调（fine tuning）。微调由以下4步构成。\n",
    "1. 在源数据集（如ImageNet数据集）上预训练一个神经网络模型，即源模型。\n",
    "2. 创建一个新的神经网络模型，即目标模型。它复制了源模型上除了输出层外的所有模型设计及其参数。我们假设这些模型参数包含了源数据集上学习到的知识，且这些知识同样适用于目标数据集。我们还假设源模型的输出层跟源数据集的标签紧密相关，因此在目标模型中不予采用。\n",
    "3. 为目标模型添加一个输出大小为目标数据集类别个数的输出层，并随机初始化该层的模型参数。\n",
    "4. 在目标数据集（如FashionMNIST数据集）上训练目标模型。我们将从头训练输出层，而其余层的参数都是基于源模型的参数微调得到的。\n",
    "<center/><img src=\"https://cdn.nlark.com/yuque/0/2021/jpeg/1508544/1614151636690-a8025370-aa39-48e5-a34e-e2fad2816cde.jpeg\"/></center>\n",
    "- 当目标数据集远小于源数据集时，微调有助于提升模型的泛化能力。\n",
    "# 加载数据集\n",
    "- FashionMNIST是28×28的灰度图片，60000/10000的训练测试数据划分，其涵盖了来自10种类别的共7万个不同商品的正面图片。\n",
    "<center/><img src=\"https://cdn.nlark.com/yuque/0/2021/png/1508544/1614153298387-a8d9fcaa-119a-4b0a-ac5e-b5f18478e077.png\"/></center>\n",
    "- 假设我们想从图像中识别出不同种类的衣物。一种可能的方法是先收集尽可能多的衣物的不同拍摄角度的图片，然后在收集到的图像数据集上训练一个分类模型，但样本数仍然不及ImageNet数据集中样本数的十分之一。这可能会导致适用于ImageNet数据集的复杂模型在这个椅子数据集上过拟合。同时，因为数据量有限，最终训练得到的模型的精度也可能达不到实用的要求。\n",
    "- 为了应对上述问题，一个显而易见的解决办法是收集更多的数据。然而，收集和标注数据会花费大量的时间和资金。例如，为了收集ImageNet数据集，研究人员花费了数百万美元的研究经费。虽然目前的数据采集成本已降低了不少，但其成本仍然不可忽略。\n",
    "- 另外一种解决办法是应用迁移学习（transfer learning），将从源数据集学到的知识迁移到目标数据集上。例如，虽然ImageNet数据集的图像大多跟衣物无关，但在该数据集上训练的模型可以抽取较通用的图像特征，从而能够帮助识别边缘、纹理、形状和物体组成等。这些类似的特征对于识别衣物也可能同样有效。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意：fashion mnist数据集加载，需要先安装ipywidgets，不然会报错提示需要升级jupyter\n",
    "!pip install ipywidgets --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "uuid": "2a6f0424-594c-4924-8b55-557269547f94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./Datasets/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/.local/lib/python3.6/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad790b8805eb47f5a8bef925c4c657d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./Datasets/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./Datasets/FashionMNIST/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./Datasets/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "573ba799cbec42438d8f49cdaa63cb53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./Datasets/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./Datasets/FashionMNIST/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./Datasets/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd010b873084acc80997b1a544e4273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./Datasets/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./Datasets/FashionMNIST/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./Datasets/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e57970128b417885fb424d1cbc19f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./Datasets/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./Datasets/FashionMNIST/FashionMNIST/raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/.local/lib/python3.6/site-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# 在CPU版本自动下载数据\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "###################fashion mnist数据集加载######################\n",
    "def load_data_fashion_mnist(batch_size, resize=None, root='./Datasets/FashionMNIST'):\n",
    "    \"\"\"Download the fashion mnist dataset and then load into memory.\"\"\"\n",
    "    trans = []\n",
    "    if resize:\n",
    "        trans.append(torchvision.transforms.Resize(size=resize))\n",
    "    trans.append(torchvision.transforms.ToTensor())\n",
    "    \n",
    "    transform = torchvision.transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=transform)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform)\n",
    "    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_iter, test_iter\n",
    "#################################################################\n",
    "batch_size = 64\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "7da02b91-af7c-4dfd-9bde-72d391aee8c4"
   },
   "source": [
    "# 模型使用\n",
    "Pytorchvision支持多种图像分类模型，这里我们选择残差网络模型作为迁移学习的基础模型，对输出层（最后一层）改为十个类别，其它特征层选择在训练时候微调参数。常见的ResNet网络模型如下：\n",
    "<img src=\"https://cdn.nlark.com/yuque/0/2021/png/1508544/1614152398516-530cf2a8-0eb7-4277-887f-c701e2b24011.png\"/>\n",
    "基于ResNet18完成网络模型修改，最终的模型实现代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "uuid": "70ff4d29-b259-4f33-adf1-a9dd6abe983b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /home/admin/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5350507d404e40e8bf87547e73834e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=46827520), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 在CPU版本自动下载模型参数\n",
    "class SurfaceDefectResNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SurfaceDefectResNet, self).__init__()\n",
    "        # Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /home/admin/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n",
    "        self.cnn_layers = torchvision.models.resnet18(pretrained=True)\n",
    "        num_ftrs = self.cnn_layers.fc.in_features\n",
    "        self.cnn_layers.fc = torch.nn.Linear(num_ftrs, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # stack convolution layers\n",
    "        out = self.cnn_layers(x)\n",
    "        return out\n",
    "\n",
    "net = SurfaceDefectResNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "822b3f83-a5ae-4b67-adee-c011ccc4bee3"
   },
   "source": [
    "# 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "uuid": "6205a198-dd41-4421-8366-77abc5ec3ad9"
   },
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "71238e65-06f2-4979-9411-b5005984648f"
   },
   "source": [
    "# 定义优化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "uuid": "3b2c0519-b31c-41a2-9399-b54bed03915c"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "83bcc538-3116-4eb0-b2e5-4013952e0442"
   },
   "source": [
    "# 定义准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "uuid": "31277a5f-01fa-4e70-b7d5-2d53283d51df"
   },
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):\n",
    "    return (y_hat.argmax(dim=1) == y).float().mean().item()\n",
    "\n",
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    for X, y in data_iter:\n",
    "        acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "72313610-9172-4b7d-828e-cce0cc3b0335"
   },
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "87dd8420-9aec-41d6-b232-79e16147ed3e"
   },
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "def train_ch(net, train_iter, test_iter, loss, num_epochs, batch_size,\n",
    "              params=None, lr=None, optimizer=None):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
    "        for X, y in train_iter:\n",
    "            X = torch.cat((X, X, X), 1)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y).sum()\n",
    "            \n",
    "            # 梯度清零\n",
    "            if optimizer is not None:\n",
    "                optimizer.zero_grad()\n",
    "            elif params is not None and params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "            \n",
    "            l.backward()\n",
    "            optimizer.step() \n",
    "            \n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))\n",
    "\n",
    "train_ch(net, train_iter, test_iter, loss, num_epochs, batch_size, None, None, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "93bd4c27-f5af-413c-a20c-2b994e54595d"
   },
   "source": [
    "# 练习题\n",
    "选择题：\n",
    "1. 假设我们将源模型的输出层改成输出大小为目标数据集类别个数的输出层，则对于这个新的输出层如何初始化  \n",
    "    a. 复制源模型的参数进行初始化  \n",
    "    b. 随机初始化参数  \n",
    "    c. 用全零初始化参数  \n",
    "    d. 不需要初始化  \n",
    "2. 假设我们将源模型的输出层改成输出大小为目标数据集类别个数的输出层，在训练过程中下列说法正确的是  \n",
    "    a. 对输出层使用较大的学习率，对其他层使用较小的学习率。  \n",
    "    b. 对输出层使用较小的学习率，对其他层使用较大的学习率。  \n",
    "    c. 对输出层和其他层使用相同大小的学习率。    \n",
    "    d. 对输出层进行微调，其他层保持参数不变，不需要学习。  \n",
    "\n",
    "答案：\n",
    "1. b\n",
    "2. a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "631b1fba-e666-4832-8bfd-0254acf57111"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "tianchi_metadata": {
   "competitions": [],
   "datasets": [],
   "description": "",
   "notebookId": "163488",
   "source": "dsw"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
