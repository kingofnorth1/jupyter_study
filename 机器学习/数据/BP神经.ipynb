{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e40bab16",
   "metadata": {},
   "source": [
    "# BP神经代码\n",
    "## 网址：https://blog.csdn.net/TYOUKAI_/article/details/78735958"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27f072d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99998046]\n",
      " [0.99999015]\n",
      " [0.99999147]\n",
      " [0.99999171]\n",
      " [0.99999176]\n",
      " [0.99999177]]\n"
     ]
    }
   ],
   "source": [
    "#! /usr/bin/python\n",
    "# -*- encoding:utf8 -*-\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def rand(a, b):\n",
    "    return (b - a) * np.random.random() + a\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "\n",
    "class BP:\n",
    "    def __init__(self, layer, iter, max_error):\n",
    "        self.input_n = layer[0]  # 输入层的节点个数 d\n",
    "        self.hidden_n = layer[1]  # 隐藏层的节点个数 q\n",
    "        self.output_n = layer[2]  # 输出层的节点个数 l\n",
    "        self.gj = []\n",
    "        self.eh = []\n",
    "        self.input_weights = []   # 输入层与隐藏层的权值矩阵\n",
    "        self.output_weights = []  # 隐藏层与输出层的权值矩阵\n",
    "        self.iter = iter          # 最大迭代次数\n",
    "        self.max_error = max_error  # 停止的误差范围\n",
    "\n",
    "        # for i in range(self.input_n + 1):\n",
    "        #     tmp = []\n",
    "        #     for j in range(self.hidden_n):\n",
    "        #         tmp.append(rand(-0.2, 0.2))\n",
    "        #     self.input_weights.append(tmp)\n",
    "        #\n",
    "        # for i in range(self.hidden_n + 1):\n",
    "        #     tmp = []\n",
    "        #     for j in range(self.output_n):\n",
    "        #         tmp.append(rand(-0.2, 0.2))\n",
    "        #     self.output_weights.append(tmp)\n",
    "        # self.input_weights = np.array(self.input_weights)\n",
    "        # self.output_weights = np.array(self.output_weights)\n",
    "\n",
    "        # 初始化一个(d+1) * q的矩阵，多加的1是将隐藏层的阀值加入到矩阵运算中\n",
    "        self.input_weights = np.random.random((self.input_n + 1, self.hidden_n))\n",
    "        # 初始话一个(q+1) * l的矩阵，多加的1是将输出层的阀值加入到矩阵中简化计算\n",
    "        self.output_weights = np.random.random((self.hidden_n + 1, self.output_n))\n",
    "\n",
    "        self.gj = np.zeros(layer[2])\n",
    "        self.eh = np.zeros(layer[1])\n",
    "\n",
    "    #  正向传播与反向传播\n",
    "    def forword_backword(self, xj, y, learning_rate=0.1):\n",
    "        xj = np.array(xj)\n",
    "        y = np.array(y)\n",
    "        input = np.ones((1, xj.shape[0] + 1))\n",
    "        input[:, :-1] = xj\n",
    "        x = input\n",
    "        # ah = np.dot(x, self.input_weights)\n",
    "        ah = x.dot(self.input_weights)\n",
    "        bh = sigmoid(ah)\n",
    "\n",
    "        input = np.ones((1, self.hidden_n + 1))\n",
    "        input[:, :-1] = bh\n",
    "        bh = input\n",
    "\n",
    "        bj = np.dot(bh, self.output_weights)\n",
    "        yj = sigmoid(bj)\n",
    "\n",
    "        error = yj - y\n",
    "        self.gj = error * sigmoid_derivative(yj)\n",
    "\n",
    "        # wg = np.dot(self.output_weights, self.gj)\n",
    "\n",
    "        wg = np.dot(self.gj, self.output_weights.T)\n",
    "        wg1 = 0.0\n",
    "        for i in range(len(wg[0]) - 1):\n",
    "            wg1 += wg[0][i]\n",
    "        self.eh = bh * (1 - bh) * wg1\n",
    "        self.eh = self.eh[:, :-1]\n",
    "\n",
    "        #  更新输出层权值w，因为权值矩阵的最后一行表示的是阀值多以循环只到倒数第二行\n",
    "        for i in range(self.output_weights.shape[0] - 1):\n",
    "            for j in range(self.output_weights.shape[1]):\n",
    "                self.output_weights[i][j] -= learning_rate * self.gj[0][j] * bh[0][i]\n",
    "\n",
    "        #  更新输出层阀值b，权值矩阵的最后一行表示的是阀值\n",
    "        for j in range(self.output_weights.shape[1]):\n",
    "            self.output_weights[-1][j] -= learning_rate * self.gj[0][j]\n",
    "\n",
    "        #  更新输入层权值w\n",
    "        for i in range(self.input_weights.shape[0] - 1):\n",
    "            for j in range(self.input_weights.shape[1]):\n",
    "                self.input_weights[i][j] -= learning_rate * self.eh[0][j] * xj[i]\n",
    "\n",
    "        # 更新输入层阀值b\n",
    "        for j in range(self.input_weights.shape[1]):\n",
    "            self.input_weights[-1][j] -= learning_rate * self.eh[0][j]\n",
    "        return error\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        for i in range(self.iter):\n",
    "            error = 0.0\n",
    "            for j in range(len(X)):\n",
    "                error += self.forword_backword(X[j], y[j])\n",
    "            error = error.sum()\n",
    "            if abs(error) <= self.max_error:\n",
    "                break\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        x_test = np.array(x_test)\n",
    "        tmp = np.ones((x_test.shape[0], self.input_n + 1))\n",
    "        tmp[:, :-1] = x_test\n",
    "        x_test = tmp\n",
    "        an = np.dot(x_test, self.input_weights)\n",
    "        bh = sigmoid(an)\n",
    "        #  多加的1用来与阀值相乘\n",
    "        tmp = np.ones((bh.shape[0], bh.shape[1] + 1))\n",
    "        tmp[:, : -1] = bh\n",
    "        bh = tmp\n",
    "        bj = np.dot(bh, self.output_weights)\n",
    "        yj = sigmoid(bj)\n",
    "        print(yj)\n",
    "        return yj\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #  指定神经网络输入层，隐藏层，输出层的元素个数\n",
    "    layer = [2, 4, 1]\n",
    "    X = [\n",
    "            [1, 1],\n",
    "            [2, 2],\n",
    "            [3, 3],\n",
    "            [4, 4],\n",
    "            [5, 5],\n",
    "            [6, 6]\n",
    "        ]\n",
    "    y = [[2.1], [3.5], [4.1], [5.2], [6.6], [6.9]]\n",
    "    # x_test = [[2, 3],\n",
    "    #           [2, 2]]\n",
    "    #  设置最大的迭代次数，以及最大误差值\n",
    "    bp = BP(layer, 10000, 0.0001)\n",
    "    bp.fit(X, y)\n",
    "    bp.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8ef4530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99999116]\n",
      " [0.99819174]\n",
      " [0.99999175]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.99999116],\n",
       "       [0.99819174],\n",
       "       [0.99999175]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = [[2,3],[10,-10],[0,10]]\n",
    "arr = bp.predict(num)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74b5f6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.70509523732522"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "num = -math.log(1/arr[2][0]-1)\n",
    "num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c1d0ef",
   "metadata": {},
   "source": [
    "# BP神经教学\n",
    "## 网址：https://www.cnblogs.com/Finley/p/5946000.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24efd12b",
   "metadata": {},
   "source": [
    "### 1、首先实现几个工具类函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12ab6d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand(a,  b):\n",
    "    return (b - a) * random.random() + a\n",
    "\n",
    "\n",
    "def make_matrix(m, n, fill=0.0):  # 创造一个指定大小的矩阵\n",
    "    mat = []\n",
    "    for i in range(m):\n",
    "        mat.append([fill] * n)\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1b2b2c",
   "metadata": {},
   "source": [
    "### 2.定义sigmod函数和它的导数:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5bd51f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + math.exp(-x))\n",
    "\n",
    "\n",
    "def sigmod_derivate(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08424522",
   "metadata": {},
   "source": [
    "### 定义BPNeuralNetwork类， 使用三个列表维护输入层，隐含层和输出层神经元， 列表中的元素代表对应神经元当前的输出值.使用两个二维列表以邻接矩阵的形式维护输入层与隐含层， 隐含层与输出层之间的连接权值， 通过同样的形式保存矫正矩阵.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbec02c",
   "metadata": {},
   "source": [
    "### 3.定义setup方法初始化神经网络:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2130df76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(self, ni, nh, no):\n",
    "    self.input_n = ni + 1\n",
    "    self.hidden_n = nh\n",
    "    self.output_n = no\n",
    "    # init cells\n",
    "    self.input_cells = [1.0] * self.input_n\n",
    "    self.hidden_cells = [1.0] * self.hidden_n\n",
    "    self.output_cells = [1.0] * self.output_n\n",
    "    # init weights\n",
    "    self.input_weights = make_matrix(self.input_n, self.hidden_n)\n",
    "    self.output_weights = make_matrix(self.hidden_n, self.output_n)\n",
    "    # random activate\n",
    "    for i in range(self.input_n):\n",
    "        for h in range(self.hidden_n):\n",
    "            self.input_weights[i][h] = rand(-0.2, 0.2)\n",
    "    for h in range(self.hidden_n):\n",
    "        for o in range(self.output_n):\n",
    "            self.output_weights[h][o] = rand(-2.0, 2.0)\n",
    "    # init correction matrix\n",
    "    self.input_correction = make_matrix(self.input_n, self.hidden_n)\n",
    "    self.output_correction = make_matrix(self.hidden_n, self.output_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2480bb",
   "metadata": {},
   "source": [
    "### 4.定义predict方法进行一次前馈， 并返回输出:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "02302cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, inputs):\n",
    "    # activate input layer\n",
    "    for i in range(self.input_n - 1):\n",
    "        self.input_cells[i] = inputs[i]\n",
    "    # activate hidden layer\n",
    "    for j in range(self.hidden_n):\n",
    "        total = 0.0\n",
    "        for i in range(self.input_n):\n",
    "            total += self.input_cells[i] * self.input_weights[i][j]\n",
    "        self.hidden_cells[j] = sigmoid(total)\n",
    "    # activate output layer\n",
    "    for k in range(self.output_n):\n",
    "        total = 0.0\n",
    "        for j in range(self.hidden_n):\n",
    "            total += self.hidden_cells[j] * self.output_weights[j][k]\n",
    "        self.output_cells[k] = sigmoid(total)\n",
    "    return self.output_cells[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7959dc97",
   "metadata": {},
   "source": [
    "### 5.定义back_propagate方法定义一次反向传播和更新权值的过程， 并返回最终预测误差:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b3a8b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagate(self, case, label, learn, correct):\n",
    "    # feed forward\n",
    "    self.predict(case)\n",
    "    # get output layer error\n",
    "    output_deltas = [0.0] * self.output_n\n",
    "    for o in range(self.output_n):\n",
    "        error = label[o] - self.output_cells[o]\n",
    "        output_deltas[o] = sigmod_derivate(self.output_cells[o]) * error\n",
    "    # get hidden layer error\n",
    "    hidden_deltas = [0.0] * self.hidden_n\n",
    "    for h in range(self.hidden_n):\n",
    "        error = 0.0\n",
    "        for o in range(self.output_n):\n",
    "            error += output_deltas[o] * self.output_weights[h][o]\n",
    "        hidden_deltas[h] = sigmod_derivate(self.hidden_cells[h]) * error\n",
    "    # update output weights\n",
    "    for h in range(self.hidden_n):\n",
    "        for o in range(self.output_n):\n",
    "            change = output_deltas[o] * self.hidden_cells[h]\n",
    "            self.output_weights[h][o] += learn * change + correct * self.output_correction[h][o]\n",
    "            self.output_correction[h][o] = change\n",
    "    # update input weights\n",
    "    for i in range(self.input_n):\n",
    "        for h in range(self.hidden_n):\n",
    "            change = hidden_deltas[h] * self.input_cells[i]\n",
    "            self.input_weights[i][h] += learn * change + correct * self.input_correction[i][h]\n",
    "            self.input_correction[i][h] = change\n",
    "    # get global error\n",
    "    error = 0.0\n",
    "    for o in range(len(label)):\n",
    "        error += 0.5 * (label[o] - self.output_cells[o]) ** 2\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77ff85b",
   "metadata": {},
   "source": [
    "### 6.定义train方法控制迭代， 该方法可以修改最大迭代次数， 学习率λ， 矫正率μ三个参数."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77805bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, cases, labels, limit=10000, learn=0.05, correct=0.1):\n",
    "    for i in range(limit):\n",
    "        error = 0.0\n",
    "        for i in range(len(cases)):\n",
    "            label = labels[i]\n",
    "            case = cases[i]\n",
    "            error += self.back_propagate(case, label, learn, correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5d71a0",
   "metadata": {},
   "source": [
    "### 7.编写test方法，演示如何使用神经网络学习异或逻辑:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e3d0c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(self):\n",
    "    cases = [\n",
    "            [0, 0],\n",
    "            [0, 1],\n",
    "            [1, 0],\n",
    "            [1, 1],\n",
    "        ]\n",
    "    labels = [[0], [1], [1], [0]]\n",
    "    self.setup(2, 5, 1)\n",
    "    self.train(cases, labels, 10000, 0.05, 0.1)\n",
    "    for case in cases:\n",
    "        print(self.predict(case))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5035db90",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "test() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Windows\\Temp/ipykernel_3448/1055655510.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: test() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    p = test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
